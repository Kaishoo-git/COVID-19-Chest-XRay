{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python312\\Lib\\site-packages\\torchxrayvision\\utils.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torchxrayvision as xrv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = xrv.datasets.COVID19_Dataset(imgpath=\"data/images/\",\\\n",
    "                                 csvpath=\"data/csv/metadata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "535"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d) # Size of dataset = 535 entries, 342(64%) of them are COVID-19 positive, 193(36%) negatives.\n",
    "# lab_test_attributes = d.pathologies # Column names\n",
    "# lab_test_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "headers = ['image', 'shape', 'covid-19', 'findings']\n",
    "for i in range(len(d)):\n",
    "    img = d[i]['img'][0]\n",
    "    shape = img.shape\n",
    "    lab = d[i]['lab']\n",
    "    \n",
    "    row = [img, shape]\n",
    "    row.append(lab[3])   # entry for covid-19\n",
    "    row.append(1.0 if re.search('COVID-19', d.csv.iloc[i][5]) else 0.0)\n",
    "    data.append(row)\n",
    "df = pd.DataFrame(data, columns = headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, low, high = df.iloc[:,0], df.iloc[:,-1], -1024, 1024\n",
    "data, target_height, target_width = [], 512, 512\n",
    "for image in X:\n",
    "    image  = 255 * (image - low) / (high - low)\n",
    "    image = cv2.resize(image, (target_width, target_height))\n",
    "    data.append(image)\n",
    "X = np.array(data).reshape(-1, target_width, target_height, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(535, 512, 512, 1) (535,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, y.shape)  # 535 datasets, of size 512 by 512, greyscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initial Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "# from keras_tuner import HyperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.4, random_state = 3244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ann = models.Sequential([\n",
    "    layers.Flatten(input_shape = (512, 512, 1)),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    layers.Dense(32, activation = 'relu'),\n",
    "    layers.Dense(1, activation = 'sigmoid')  # For binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam',\n",
    "            loss = 'binary_crossentropy',\n",
    "            metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(16, (3, 3), activation = 'relu', input_shape = (512, 512, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation = 'relu'),\n",
    "    # layers.Dropout(0.5),  # Helps prevent overfitting\n",
    "     \n",
    "    layers.Dense(1, activation = 'sigmoid')  # For binary classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam',\n",
    "            loss = 'binary_crossentropy',\n",
    "            metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 0.6499 - loss: 6211.8687\n",
      "Epoch 2/5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.4816 - loss: 5555.7017\n",
      "Epoch 3/5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.5968 - loss: 1906.2186\n",
      "Epoch 4/5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.6256 - loss: 709.0164\n",
      "Epoch 5/5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 0.7068 - loss: 502.0346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b7b2aff9b0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(Xtrain, ytrain, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 645ms/step - accuracy: 0.5792 - loss: 481.0723\n",
      "Epoch 2/5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 649ms/step - accuracy: 0.5445 - loss: 41.9315\n",
      "Epoch 3/5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 643ms/step - accuracy: 0.5326 - loss: 2.5553\n",
      "Epoch 4/5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 650ms/step - accuracy: 0.5151 - loss: 0.6968\n",
      "Epoch 5/5\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 651ms/step - accuracy: 0.6295 - loss: 0.5803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b7b2b03740>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(Xtrain, ytrain, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.42      0.89      0.57        83\n",
      "         1.0       0.76      0.21      0.33       131\n",
      "\n",
      "    accuracy                           0.48       214\n",
      "   macro avg       0.59      0.55      0.45       214\n",
      "weighted avg       0.63      0.48      0.42       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ann_pred = ann.predict(Xtest)\n",
    "ann_pred_classes = [np.round(element) for element in ann_pred]\n",
    "print(\"Classification report: \\n\", classification_report(ytest, ann_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.04      0.07        83\n",
      "         1.0       0.61      0.95      0.74       131\n",
      "\n",
      "    accuracy                           0.60       214\n",
      "   macro avg       0.47      0.50      0.40       214\n",
      "weighted avg       0.50      0.60      0.48       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_pred = cnn.predict(Xtest)\n",
    "cnn_pred_classes = [np.round(element) for element in cnn_pred]\n",
    "print(\"Classification report: \\n\", classification_report(ytest, cnn_pred_classes)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 60,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 931ms/step - accuracy: 0.5333 - loss: 1762.8212\n",
      "Epoch 2/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 932ms/step - accuracy: 0.5644 - loss: 3.2285\n",
      "Epoch 3/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 928ms/step - accuracy: 0.6792 - loss: 0.6939\n",
      "Epoch 4/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 932ms/step - accuracy: 0.6662 - loss: 0.6916\n",
      "Epoch 5/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 880ms/step - accuracy: 0.6426 - loss: 0.6904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25f8312c950>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(Xtrain, ytrain, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234ms/step - accuracy: 0.6385 - loss: 0.6897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6899442076683044, 0.6296296119689941]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.6425 - loss: 0.6892\n",
      "Epoch 2/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.6455 - loss: 2.3894\n",
      "Epoch 3/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - accuracy: 0.6183 - loss: 0.6877\n",
      "Epoch 4/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1s/step - accuracy: 0.6279 - loss: 0.7932\n",
      "Epoch 5/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 0.6478 - loss: 0.6837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25f83112480>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(datagen.flow(Xtrain, ytrain, batch_size = 32), epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step - accuracy: 0.6385 - loss: 0.6799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6821554899215698, 0.6296296119689941]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
